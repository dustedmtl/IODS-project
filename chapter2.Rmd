# Chapter 2: Regression and model validation

*Data analysis*

```{r}
date()
```

The dataset that is read in contains averaged survey scores for three subjects, student attitude, exam points, age, and gender. There are 166 students.

```{r}
lr2 <- read.table('data/learning2014.csv', sep=',', header = T)
dim(lr2)
```

```{r}
summary(lr2)
```

```{r}
library(ggplot2)
library(GGally)
p <- ggpairs(lr2, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))

# draw the plot
p
```

The score variables deep, surf and stra are distributed between 1 and 5.

Correlations in the data:

-   points and attitude are strongly correlated

-   points and stra are also correlated; likewise points and surf (negative correlation)

-   age skews young and it isn't strongly correlated with anything.

## Linear regression

Linear regression is used to determine relation between a response variable and one of more (if multiple regression) explanatory variables. For a single variable, the equation to solve is:

$Y = \alpha + \beta X + \epsilon$

where all the terms are $N$-dimensional vectors (for $N$ observations). $Y$ is the response variable and $X$ is the explanatory variable. The $\epsilon$ error term is assumed to normally distributed with a mean of 0.

The task is to find such coefficients for $\alpha$ and $\beta$ that minimize the sum $\sum_{i=1}^{N} \epsilon_i^2$. This is called the least squares method.

For multiple linear regression the equation would be similarly $Y = \alpha + X\beta  + \epsilon$, where $X$ would be a matrix of dimensions $N * k$ (with $k$ explanatory variables) instead of a $N * 1$-dimensional vector.

Linear regression model for variable points based on three explanatory variables: attitude, stra and surf:

```{r}
model <- lm(points ~ attitude + stra + surf, data = lr2)

summary(model)
```

The test that the fitting is done is omnibus F-test, which tests the hypothesis that coefficients for all three variables are zero. The very low p-value for intercept means that this hypothesis is not likely to be true.

The p-value for attitude (below 0.05) shows that the model fitting is reliable for it.

Multiple R squared value of 0.2074 means that the three variables account for 20 % of variation.

```{r}

# All four in the same plot
par(mfrow = c(2,2))

plot(model, which = c(1,2,5))

```

Above are three plots regarding residuals, where residual is a difference between the fitted and actual value.

The first plot (residuals vs fitted) is symmetrical and there is no correlation between residual and fitted value. Linear regression model is appropriate here.

The second plot shows quantiles against each other. This plot is linear too, so linear regression model is still valid.

The last plot uses standardized residuals with identical variance. The result is similar to plot 1.
